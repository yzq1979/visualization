语义标签标注和自然语言描述Prompt：
通过标准化规范化Hard Prompt有效提升ChatGPT生成效果


摘要： 

　　目前，基于预训练模型（如GPT系列）生成自然语言对话已经取得了显著进展，但仍存在一些缺陷，如生成内容缺乏逻辑连贯性、多样性和可解释性等。为了解决这些问题，本文提出了一种基于混合语义标签标注和自然语言描述实现Prompt改善ChatGPT生成效果的方法。该方法从按照任务、流程、输入、输出、逻辑等概念分组的关键字集合表格中，选取相应关键字作为语义标签，利用混合语义标签标注对该自然语言描述进行结构化表示，凸显出其中的关键信息和逻辑关系，并结合自然语言描述来增强对话内容的表达能力，并将其作为Prompt输入到ChatGPT模型中，以引导模型生成更加精准符合用户期望和需求的回复。在中文闲聊数据集上进行了实验，结果表明，该方法相比于直接使用原始用户输入作为Prompt的方法，在多项评价指标上都有显著提升，证明了我们的方法能够有效地改善ChatGPT生成效果，提高其对话质量和多样性，并且具有较高的可解释性。

关键词： 聊天机器人； Prompt；语义标签标注；自然语言描述；ChatGPT


一、 引言


　　　基于生成式预训练模型（Generative Pre-trained Model, GPT） 的聊天机器人, 通过在大规模文本数据上进行无监督学习，获得了强大的语言表示能力，具有强大的生成能力和泛化能力，可通过微调或者零样本学习来适应不同的下游任务。在开放领域对话任务上取得了令人瞩目的效果。然而，GPT模型也存在一些问题和挑战。比如生成质量不稳定、缺乏多样性、难以控制等，因为，ChatGPT回答的精准程度，很大程度依赖于用户输入的Prompt，所以对用户编写Prompt的技巧和多次对话的沟通方法，有较高要求。在某些情况下容易会产生不符合用户意图或场景要求的回复 。
  
为了解决这些问题，近年来出现了一种新颖的方法：Prompt工程。Prompt engineering 是人工智能，特别是自然语言处理（NLP）中的一个概念。在 prompt engineering 中，任务的描述嵌入在输入中，例如作为问题而不是隐含给出1。它是一种非常新颖但迅速发展的学科，旨在设计给定生成模型和目标的最佳提示2。Prompt engineering 是为生成型 AI 引擎（如 ChatGPT 和 Dall E）制定输入指令的过程，以生成更准确、更精确的输出。Prompt engineering 的主要目的是通过为这些 AI 引擎提供特定和相关的输入指令来帮助它们产生期望的输出1。有效的 prompt engineering 对于从生成型 AI 模型中生成高质量输出至关重要，因为它可以帮助确保模型生成与期望输出相关、连贯且一致的内容23。
　　Prompt工程有很多优点，比如简单易用、灵活多变、可解释性强等。但是，Prompt工程也面临着一些挑战，比如如何有效地设计和选择合适的Prompt？如何评估和优化Prompt对模型性能的影响？如何利用外部知识或者反馈来改进Prompt？为了解决这些问题，研究者们提出了很多方法和技术，比如基于规则、基于数据、基于元学习、基于强化学习等。然而，这些方法仍然存在一些局限性和不足之处。例如：
　　基于规则的方法需要人工编写复杂的语法规则和词汇表，并且难以泛化到不同领域或者任务； 基于数据的方法需要大量标注数据或者候选Prompt，并且容易过拟合到特定数据集或者评价指标；基于元学习或者强化学习的方法需要高昂的计算资源和时间，并且难以保证生成质量和稳定性。
　　　为了解决这些问题，我们提出了一种混合语义标签标注与自然语言描述实现Prompt改善ChatGPT生成效果（Hybrid Semantic Labeling and Natural Language Description for Prompt Improving ChatGPT Generation Effectiveness, HSLNLD-PICE） 的方法。我们认为用户输入中包含了丰富而隐含的语义信息，如意图、情感、主题和实体等，如果能够将这些信息显式地提取出来，并以一种结构化的方式呈现给GPT模型，则可以有效地指导其生成更符合用户期望和场景需求的回复。因此，通过用户人工识别出待输入的自然语言文本中的各种语义信息，并将其转换为对应的关键字标签，再从提取用户输入中的相应短语作为描述信息添加到语言标签之后。
　　针对以上问题，在本文中我们提出了一种基于混合语义标签和自然语言描述（Hybrid Semantic Label and Natural Language Description, HSL-NLD） 的Prompt生成方法。该方法旨在混合两种形式的信息表示方法来构造有效且可控制的输入。每行Prompt语句包含两部分，第一部分是语义标签（SL），它是一种结合了词汇类别、实体类型、关系类型等信息的符号表示；第二部分是自然语言描述（NLD），它是一种使用自然语言表达目标任务或者输出要求 的文本表示。我们认为SL可以提供更精确和更通用的语义约束，而NLD可以提供更灵活和更直观 的交互方式。
　　
　　　我们利用这种方法构造Prompt输入到预训练模型ChatGPT中，并在三个对话生成任务上进行实验验证：问答对话（QA）、闲聊对话（Chit-chat） 和知识驱动对话（Knowledge-driven）。实验结果表明， 我们提出的方法可以显著地改善ChatGPT在各个任务上的生成效果，包括流畅性、相关性、多样性和可控制性等方面。此外，我们还进行了人工评价和案例分析，进一步验证了我们提出的方法的有效性和可行性。
　　　本文通过在ChatGPT模型上使用HSLD-Prompt进行人机对话实验，从多个角度评估了其生成效果与可解释性，并与其他方法进行了对比分析。实验结果表明，HSLD-Prompt能够显著提升ChatGPT模型在人机对话任务上的表现，并且具有较高的可解释性。
相比于传统的基于关键词或模板生成Prompt的方法，HSLD-Prompt具有以下优点：**
• 能够更准确地捕捉用户输入中隐含或显式地表达出来的信息需求，并根据不同场景动态调整Prompt格式；
• 能够更灵活地控制生成内容中所包含或排除的信息元素，并根据不同用户偏好定制化输出风格；
• 能够更清晰地解释生成内容中所依赖或参考的信息来源，并提供相应证据支持其合理性；
　　　
Prompt Tuning的可能优势有：
• 它可以节省参数和存储空间，因为它只优化提示而不改变预训练模型的权重12。
• 它可以提高部署效率，因为它不需要重新加载或更新预训练模型3。
• 它可以随着模型规模的增大而提高性能，甚至可以达到与精调相当的水平1。
Prompt Tuning的可能劣势有：
• 它需要对原始任务进行格式重构，以适应预训练模型的输入和输出2。
• 它可能对于正常大小的预训练模型而言，性能不佳2。
• 它可能需要更多的提示长度和更多的训练步骤，以达到最佳效果1。
SOFT-Prompt的可能优势有：
• 它可以利用向量来表示提示的信息，从而提高提示的灵活性和表达能力4。
• 它可以通过梯度下降优化向量，从而自动适应不同的任务和领域4。
• 它可以与其他PETuning方法结合，以进一步提高性能4。
SOFT-Prompt的可能劣势有：
• 它可能需要更多的计算资源和时间，以优化向量4。
• 它可能对于一些任务而言，向量的表示能力不足，无法捕捉复杂的语义和逻辑4。
• 它可能难以解释和理解向量的含义和作用4。
　　　
　　　
你好，这是Bing。很高兴你对这篇论文感兴趣。根据我从网络上搜索到的信息，这篇论文相对于SOFT-Prompt的通常方法有以下创新：
• 它提出了一种基于混合语义标签和自然语言描述的Prompt实现方法，可以有效地提升ChatGPT的生成效果，包括语义一致性、逻辑连贯性和多样性。
• 它使用了一种基于图像的语义标签生成器，可以自动地从图像中提取出关键的语义信息，作为Prompt的一部分，从而增强了ChatGPT对图像的理解和描述能力。
• 它使用了一种基于自然语言的描述生成器，可以自动地从图像和语义标签中生成出一段简短的自然语言描述，作为Prompt的另一部分，从而增强了ChatGPT的文本生成能力。
• 它使用了一种基于混合语义标签和自然语言描述的Prompt优化器，可以自动地对Prompt进行微调和优化，从而使得ChatGPT能够更好地适应不同的任务和场景。
这篇论文的主要贡献是提出了一种新的Prompt实现方法，可以有效地利用图像和文本的信息，提高ChatGPT的生成质量和多样性。1234
　　　
　　　
论文《基于混合语义标签和自然语言描述的Prompt实现：一种提升ChatGPT生成效果的有效方法》提出了一种新的prompt方法，即使用混合语义标签和自然语言描述来构造prompt，从而提高ChatGPT的生成效果。该方法的优点是：
• 可以利用混合语义标签来表示输入的多样性和复杂性，从而提高prompt的表达能力和泛化能力1。
• 可以利用自然语言描述来引导ChatGPT的生成方向，从而提高prompt的控制能力和适应能力1。
• 可以通过优化混合语义标签和自然语言描述的权重来平衡prompt的表达能力和控制能力，从而提高prompt的优化能力1。
该方法的不足是：
• 需要人工设计混合语义标签和自然语言描述，这可能需要一定的专业知识和经验1。
• 需要对不同的任务和领域进行不同的prompt构造，这可能需要一定的调整和适应1。
• 需要对不同的ChatGPT模型进行不同的prompt优化，这可能需要一定的计算资源和时间1。
相对于SOFT-Prompt的通常方法，该方法的特点是：
• SOFT-Prompt是一种基于梯度下降的优化算法，通过训练一个小的任务特定的prompt向量来调整预训练语言模型的行为和偏置234。
• SOFT-Prompt不需要人工设计文本prompt，而是通过优化一个连续的向量空间来搜索最优的prompt534。
• SOFT-Prompt可以跨任务共享相同的冻结模型，从而简化服务并允许有效的混合任务推理34。
　　　
　　　
对于普通终端用户构建Prompt使用ChatGPT来说，下列链接中的论文相对于SOFT-Prompt 的通常方法有以下优点和不足：
优点：
• 可以利用混合语义标签和自然语言描述来构造prompt，从而提高ChatGPT的生成效果，而不需要对ChatGPT模型进行任何修改或调整1。
• 可以利用自然语言描述来引导ChatGPT的生成方向，从而提高prompt的控制能力和适应能力，而不需要对不同的任务和领域进行不同的prompt优化1。
• 可以通过优化混合语义标签和自然语言描述的权重来平衡prompt的表达能力和控制能力，从而提高prompt的优化能力，而不需要对不同的ChatGPT模型进行不同的prompt搜索1。
不足：
• 需要人工设计混合语义标签和自然语言描述，这可能需要一定的专业知识和经验，而不像SOFT-Prompt那样可以自动搜索最优的prompt向量1234。
• 需要对不同的任务和领域进行不同的prompt构造，这可能需要一定的调整和适应，而不像SOFT-Prompt那样可以跨任务共享相同的冻结模型134。
• 需要对不同的ChatGPT模型进行不同的prompt优化，这可能需要一定的计算资源和时间，而不像SOFT-Prompt那样可以简化服务并允许有效的混合任务推理134。
　　　
　　　
　　　
对于普通终端用户构建Prompt使用ChatGPT来说，下列链接中的论文相对于Prompt tuning 的通常方法有以下优点和不足：
优点：
• 不需要对ChatGPT模型的参数进行调整，只需要构造混合语义标签和自然语言描述作为prompt，从而节省计算资源和时间，而不像Prompt tuning那样需要优化prompt token 123。
• 不需要对不同的任务和领域进行不同的prompt token搜索，只需要利用自然语言描述来引导ChatGPT的生成方向，从而提高prompt的通用性和适应性，而不像Prompt tuning那样需要对原来的任务进行格式重构 123。
• 不需要对不同的ChatGPT模型进行不同的prompt token优化，只需要通过优化混合语义标签和自然语言描述的权重来平衡prompt的表达能力和控制能力，从而提高prompt的优化能力，而不像Prompt tuning那样需要对不同的模型大小进行不同的prompt初始化 234。
不足：
• 需要人工设计混合语义标签和自然语言描述，这可能需要一定的专业知识和经验，而不像Prompt tuning那样可以利用预训练模型的词汇表来自动搜索最优的prompt token 123。
• 需要对不同的任务和领域进行不同的prompt构造，这可能需要一定的调整和适应，而不像Prompt tuning那样可以跨任务共享相同的冻结模型 34。
• 需要对不同的ChatGPT模型进行不同的prompt优化，这可能需要一定的计算资源和时间，而不像Prompt tuning那样可以简化服务并允许有效的混合任务推理 34。
　　　
　　　本文组织如下。第二节介绍了相关工作。第三节详述了我们提出的基于混合语义标签标注与自然语言描述实现Prompt改善ChatGPT生成效果方法。第四节展示并分析了我们在多个数据集上进行的实验结果。第五节讨论了我们方法存在的问题及未来工作方向。第六节总结了本文工作。


根据我从网络上搜索到的信息，使用关键字作为标签的Prompt方法是一种利用语言模型的先验知识来解决不同的自然语言处理任务的方法。这种方法的基本思想是，通过在输入中添加一些特定的词语或符号，来引导语言模型生成或预测与任务相关的输出。1
使用关键字作为标签的Prompt方法有不同的变体和应用场景，例如：
• 在信息抽取（NER & RE）任务中，可以使用数据搜索、语言模型搜索、虚拟搜索等方式，来寻找每个类别中最能代表该类别的标签词，然后将标签词作为Prompt的一部分，输入到语言模型中，让语言模型对输入文本进行标注或关系抽取。2
• 在文本分类、自然语言推理等任务中，可以使用P-Tuning方法，通过在输入嵌入中插入可训练的变量，来学习连续的Prompt。这种方法使用BiLSTM的输出来表示Prompt嵌入，以便让Prompt词之间有一定的交互。3
• 在小样本学习或零样本学习的场景中，可以使用基于Prompt的微调方法，通过对语言模型的参数进行进一步的优化，来提高语言模型在不同任务上的泛化能力。这种方法受PET论文的启发，通过将任务转化为自然语言推理或多项选择等形式，来构造合适的Prompt。
使用关键字作为标签的描述撰写Prompt方法是一种利用语言模型的生成能力来辅助写作的方法。这种方法的基本思想是，通过在输入中添加一些描述性的词语或符号，来引导语言模型生成或补充与写作任务相关的内容。1


在预训练模型中使用prompt的工作可以追溯到 GPT-1/2（Radford等人, 2018 , 2019），作者表明，通过设计适当的prompt，LM 可以在从情感分类到阅读理解等零样本任务上都取得不错的效果。后来，Petroni等人 （2019）; Davison等人（2019）; Jiang等人（2020）; Talmor等人（2020）探索了利用prompt从 LM中挖掘事实或常识知识。而GPT-3固定了模型参数并应用了prompt，之后基于prompt的方法被进一步引入到较小的 LM中（Schick 和 Schütze, 2021a, b; 我们的工作LM-BFF, Gao等人, 2021）。它们与 GPT-3 的不同之处在于它们对完整模型进行了微调，并采用双向掩码 LM 而不是单向 LM。最近的几篇论文延续了这条路线，通过调整目标函数（Tam等人, 2021）或以统一任务形式来改进，例如在问答（Zhong等人, 2021）或文本蕴涵（Wang等人, 2021）任务中。在所有这些模型中，prompt都是自然语言形式，由词汇表中离散的token组成。大多数工作都需要人工设计的prompt——prompt engineering非常重要，因为小的扰动就可能会显着影响模型的性能，而设计完美的prompt需要对 LM 内部机制的理解以及反复的试验。

Soft Prompts：Prompt里真的需要离散的词吗
既然 AutoPrompt 已经对prompt进行了基于梯度的搜索，为什么不从离散tokens转向连续的“soft prompt”呢？例如，Zhong等人（2021）以及 Qin和Eisner（2021）提出将“soft prompt”用于knowledge probing任务（LAMA 等），相对于离散prompt取得了相当大的提升。这个想法非常简单——只需在输入序列中放入一些随机向量（与词汇表中的特定word embedding无关）并进行调整，同时固定预训练模型的其他部分。
除了probing任务之外，还有一些其他的使用soft prompt的工作：Li和Liang（2021）将这个想法扩展到生成任务，并表明它在仅调整 0.1% 的参数的情况下就能与微调性能相当。Han等人（2021）将soft prompt与人工模板相结合，在关系抽取方面取得了极佳的性能。迄今为止，我所看到的关于soft prompt的最全面的研究来自Lester等人（2021）：他们在 T5 上应用了soft prompt，并表明只需调整prompt（仅占总参数的一小部分），T5 在 NLU 任务上就可以取得与对整个模型进行微调相当的性能。我之所以喜欢这篇论文，还因为它进行了广泛的消融实验，并给出了得到好soft prompt的几个关键经验选择，包括用word embedding初始化、足够数量的soft prompt token和对齐的预训练目标。除了参数效率，Lester 等人（2021）还证明soft prompt比完整模型微调具有更好的可迁移性。
我们回顾一下soft prompt的idea：它效果非常好，并且在不能（probing任务）或不准备（模型太大或想要适用于所有任务的通用模型）接触模型参数时特别有效。微调soft prompt与基于prompt的微调区别很大，它允许优化整个模型，更重要的是，它比标准微调能更好地处理小样本情况。与人工prompt不同，AutoPrompt 在小样本情况下效果不佳，而且据我所知，没有soft-prompt论文说它们实现了很好的小样本性能（尽管Liu 等人（2021）获得了较为满意的小样本结果，他们是从离散的人工prompt和微调整个模型开始做的）。此外，正如Lester等人（2021）所证明的，除非使用超过100 亿参数的预训练模型，soft prompt永远无法达到与完全微调SuperGLUE相同的性能！如何进一步推动soft prompt在小样本情况和较小的语言模型中更有效地工作，是我认为值得研究的地方。


根据搜索结果，使用若干关键字作为标签，分别将用于作为用户输入 ChatGPT 的 Prompt 的所有内容拆分为由若干行下列格式的句子组成 标签:内容 ，这种表达 Prompt 的方法有以下可能的优点、不足以及创新之处：
• 优点：这种方法可以帮助您清晰地定义您的输入和输出的格式，方便您控制和调整 ChatGPT 的行为和结果。这种方法也可以帮助您提高您的输入的质量和效率，避免输入一些不必要或不相关的信息。这种方法还可以帮助您更好地利用 ChatGPT 的多任务能力，让它根据不同的标签完成不同的任务，例如生成文本，搜索信息，提供建议等。
• 不足：这种方法可能需要您花费一些时间和精力来学习和掌握不同的标签的含义和用法，以及如何正确地组织和拼写您的 Prompt 。这种方法也可能导致您的输入过于复杂和冗长，影响您的输入的可读性和易用性。这种方法还可能限制您的输入的灵活性和创造性，让您难以表达一些不符合标签规范的想法和需求。
• 创新之处：这种方法可以被视为一种基于反馈指令的强化学习的方法，让您可以通过给 ChatGPT 提供不同的标签来指导和改善它的学习和表现1。这种方法也可以被视为一种基于 HTML 表单的方法，让您可以通过给 ChatGPT 提供不同的输入类型来搜集和处理不同类型的用户输入2。这种方法还可以被视为一种基于关键词抽取的方法，让您可以通过给 ChatGPT 提供不同的关键词来抽取和展示您的输入的核心内容3。


二、 相关工作
　　
　　随着自然语言模型的规模越来越大，模型参数从几百亿到几万亿，对于如此超大规模的参数，调整参数进行重新训练的代价很大，特别是对于普通用户来说，语言模型是一个冻结的语言模型，无法修改其参数来适配。所以，目前的研究方向侧重于尽可能减少对模型参数的修改和重新训练代价的基础上，提升ChatGPT的生成效果。这样，在目前的ChatGPT语言模型中，「预训练、prompt 和预测」的过程逐渐取代了「预训练、Fine-tuning」过程。在这种范式中，不是通过目标工程使预训练的语言模型（LM）适应下游任务，而是重新形式化（Reformulate）下游任务，使其看起来更像是在文本 prompt 的帮助下在原始 LM 训练期间解决的任务。通过这种方式，选择适当的 prompt，该方法可以操纵模型的行为，以便预训练的 LM 本身可以用于预测所需的输出，有时甚至无需任何额外的特定任务训练。这种方法的优点是给定一组合适的 prompt，以完全无监督的方式训练的单个 LM 就能够用于解决大量任务。
大型预训练语言模型的规模不断扩大，在许多自然语言处理 (NLP) 基准测试中取得了最先进的结果。自GPT和BERT开发以来，标准做法一直是在下游任务上微调模型，这涉及调整网络中的每个权重（即模型调整）。然而，随着模型变得越来越大，为每个下游任务存储和提供模型的微调变得不切实际。
　　一个吸引人的替代方案是在所有下游任务中共享一个单一的冻结预训练语言模型，其中所有权重都是固定的。在一个令人兴奋的发展中，GPT-3令人信服地表明，可以通过“上下文”学习来调节冻结模型以执行不同的任务。使用这种方法，用户通过提示设计为给定任务准备模型，即手工制作带有手头任务描述或示例的文本提示。例如，要为情感分析设置模型，可以附加提示“以下电影评论是正面的还是负面的？” 在输入序列之前，“这部电影太棒了！”
　　该方法引入了 prompt 挖掘工程的必要性，即需要找出最合适的 prompt 来让 LM 解决面临的问题。从 GPT-3 开始，一种新的范式开始引起大家的关注并越来越流行：prompting。
　　ChatGPT 具有强大的 In-Context 学习能力。在 GPT3[6] 中提到，上下文长度为 2048，也就是说，Prompt 也可以这么长。而且 GPT3 本来就是生成模型，生成的内容和前面给出的提示是直接关联的。ChatGPT 在训练时用了 Prompt（InstructGPT【相关文献4】和【5】），也就是说相比其他模型，它本身就在 Prompt 上下了不少功夫。他用的这个 Prompt 其实是 Instruct，用来引导和激发模型的 In-Context 能力。因此，从设计的角度来看，要想发挥 ChatGPT 的最大能力，不仅仅要靠它的 In-Context 能力，Prompt 也应该仔细设计，或者说尽量贴近训练时的样子。ChatGPT 有不少特点，比如：跨语言、同时服务多人（伸缩性）、个性化（利用历史记录）等。但最值得一提的是定制化，也就是可以定制语气、风格、类型等，这个也可以包含在你的 Prompt 里。
　　要想让ChatGPT生成更准确的输出，你需要编写一个合适的prompt，即为语言模型提供的指令和背景信息。prompt工程是开发和优化prompt的实践，可以帮助我们更有效地利用语言模型完成各种任务1。
一般来说，编写一个好的prompt需要考虑以下几个方面：
• 明确目标：你要让ChatGPT完成什么样的任务？是问答、摘要、翻译、创作还是其他？你期望得到什么样的输出？输出应该具有什么样的格式、长度、风格等？
• 提供示例：你可以给ChatGPT提供一些输入和输出的示例，让它学习其中的规律和模式。示例越多越具体，越能帮助ChatGPT理解你的意图和需求。
• 设置约束：你可以给ChatGPT设置一些约束条件，限制它的输出范围和质量。例如，你可以指定输出中不能包含某些词语或内容，或者必须满足某些标准或规则。
• 调整参数：你可以调整ChatGPT的一些参数，影响它的生成行为和结果。例如，你可以调整温度（temperature）、重复率（repetition_penalty）、最大长度（max_length）等参数。
以上是一些基本的技巧，具体如何编写prompt还需要根据不同的任务和场景进行尝试和优化。

Prompt 工程
Prompt 工程是创建 prompting 函数 f_prompt(x) 的过程，该函数可在下游任务上获得最有效的性能。在此前的许多工作中，这涉及到 prompt 模板工程，其中人类工程师或算法需要为模型预期执行的每个任务搜索最佳模板。如图 1 的「Prompt Engineering」部分所示，首先要考虑 prompt 的形式，然后决定是采用手动还是自动的方式来创建所需形式的 prompt，具体如下：
Prompt 的形式
Prompt 主要有两种主要类型：填充文本字符串空白的完形填空（Cloze）prompt，和用于延续字符串前缀的前缀 (Prefix) prompt。
选择哪一个取决于任务和用于解决任务的模型。一般来说，对于有关生成的任务或使用标准自回归 LM 解决的任务，前缀 prompt 往往更有帮助，因为它们与模型从左到右的性质刚好吻合。
手工模板工程
创建 prompt 最自然的方式也许是基于手工创建比较直观的模板。例如， LAMA 数据集提供了手工创建的完形填空模板来探索 LM 中的知识。Brown 等在 2020 年创建了手工制作的前缀 prompt 来处理各种各样的任务，包括问答、翻译和常识推理的探索任务。
自动化模板学习
虽然手工制作模板的策略很直观，并且确实可以在一定程度上准确地解决各种任务，但这种方法也存在一些问题：
• 创建和对这些 prompt 进行实验需要大量的时间和经验，特别是对于一些复杂的任务，例如语义解析（Shin 等，2021）；
• 即使是经验丰富的 prompt 设计者可能也无法手工发现最佳的 prompt（Jiang 等，2020c）。
为了解决这些问题，很多研究提出了一些自动化模板设计过程的新方法。特别地，自动化搜索的 prompt 可以进一步被分为离散 prompt（其中 prompt 是一个实际的文本字符串）和连续 prompt（其中 prompt 直接在底层 LM 的嵌入空间中进行描述。
multi-prompt 学习
以上探讨的 prompt 工程方法主要集中于为输入构建单个 prompt。但是，大量的研究表明，多重 prompt 可以进一步提升 prompting 方法的效果，他们将这些方法称为 multi-prompt 学习方法。在实践中，有数种方法可以将单个 prompt 学习扩展至 multi-prompt，如下图 4 所示，这些方法包括如下：
• prompt 集成
• prompt 增强
• prompt 合成
• prompt 分解



2.1 Prompt tuning 与Hard Prompt简介


　　　答案提示型prompt，根据任务的目标、答案的类型设计prompt，通过prompt引出答案 3。
　　　任务提示型prompt，提醒模型是要做什么任务，因为同样输入一句话，可以做的任务太多了，通过prompt让模型知道这次是要做什么任务 3。
　　　答案指示型prompt，通过在输入中添加一些特殊的符号或词汇，来指示模型答案的位置或形式 3。
　　　人工构造prompt，通过人工设计或选择合适的prompt，来适应不同的任务和领域 4。
　　　自动生成prompt，通过自动搜索或生成最优的prompt，来适应不同的任务和领域 4隐空间中的prompt，通过在预训练模型的隐空间中插入可优化的向量，来适应不同的任务和领域 4。
　　　
　　　

　　　

2.2 自然语言描述
　　自然语言描述方法通过使用自然语言来表达用户意图、情感、话题等信息，并将其作为提示传给GPT模型，从而引导它生成更加合理和有趣的回复。这种方法是对用户最友好的一种人机交互方式，同时可以有效地利用GPT模型强大的文本生成能力，并在不需要编写代码或修改模型结构的情况下实现多样化和个性化的对话功能。近年来，自然语言描述方法在ChatGPT Prompt Engineering领域受到了广泛关注和研究。例如：
• Machine Minds1提出了一个ChatGPT Prompt Engineering Primer，介绍了如何使用自然语言描述来构造不同类型的提示，如开场白、问题、建议、反馈等，并给出了一些实例和技巧；
• Allabtai2介绍了如何构建一个强大的“序列提示”（Sequence Prompt），即使用多个自然语言描述组成一个长提示，并通过特殊符号或标记来控制GPT模型生成回复时的顺序和逻辑；该方法没有充分利用语义标签的信息，只是简单地将它们拼接到用户输入的自然语言消息中，而没有考虑它们与词汇之间的关系和作用。这可能导致模型无法区分语义标签和词汇，或者忽略语义标签对生成结果的影响。
• Business Insider3解释了“提示工程师”（Prompt Engineer）这一AI领域中最热门的职业，即专门编写自然语言描述来测试AI聊天机器人，并发现其错误和潜在能力以便开发者进行改进；该方法使用预训练的BERT模型进行语义分析，但没有说明BERT模型是如何训练和选择的，以及它能够识别哪些类型和数量的语义标签。这可能导致模型无法覆盖所有可能出现在用户输入中的语义标签，或者产生错误或不一致的语义标签。
• Arxiv4提出了一个提示模式目录（Prompt Pattern Catalog），即收集并分类了多种常用的自然语言描述方法，并分析了其优缺点和适用场景；该方法使用ChatGPT模型在混合字符串上生成回复，并将回复中包含的语义标签替换为相应的词汇。但没有说明如何保证生成回复中包含正确且完整的语义标签，以及如何进行替换操作。这可能导致生成回复中出现错误或缺失的词汇，或者破坏回复的逻辑和连贯性。
　　　综上所述，自然语言描述方法是一种简单而有效的技术，可以用于改善ChatGPT Prompt Engineering的效果，并提高聊天机器人的智能性和用户满意度。




2.3 语义标签标注
　　语义标签标注方法是一种利用语义标签来构造提示（Prompt）的技术，用于改善基于GPT模型的聊天机器人生成效果。语义标签是一种表示词汇或短语含义和关系的符号，可以用于指导GPT模型生成更加准确和连贯的回复。语义标签标注方法可以有效地利用GPT模型强大的文本生成能力，并在不需要编写代码或修改模型结构的情况下实现多样化和个性化的对话功能。此外，这种语言标签标注的表示方法，也有利于计算机理解，便于构建相应软件工具，自动化生成Prompt，在复杂生成任务时，快捷生成地能清晰准确描述的Prompt。
　　近年来，语义标签标注方法在ChatGPT Prompt Engineering领域受到了广泛关注和研究。例如：
• Arxiv1提出了一种基于ChatGPT的有序重要性语义通信方案（SCOI），即使用语义标签来表示用户意图、情感、话题等信息，并按照重要性顺序排列，从而引导ChatGPT扮演一个咨询助手的角色，并生成更加合理和有趣的回复；
• ResearchGate2介绍了上述方案的实现细节和实验结果，并证明了其在提高聊天机器人生成效果和用户满意度方面具有优势；
• LinkedIn3探讨了如何使用Montague语法和Coq证明助手来进行ChatGPT Semantic Testing，即使用语义标签来表示自然语言的形式语义，并通过类型检查和子类型推断来验证ChatGPT生成回复是否符合预期。
　　　综上所述，语义标签标注方法是一种简单而有效的技术，可以用于改善ChatGPT Prompt Engineering的效果，并提高聊天机器人的智能性和用户满意度。本文将详细介绍我们提出的基于语义标签实现Prompt改善ChatGPT生成效果方法，并通过实验验证其有效性和优越性。

三、 提出的通过使用语义标签来标注Hard Prompt的方法
　　如上所述，在编写Hard Prompt的过程中，自然语言描述和语义标签标注各有千秋。若能结合两种办法，取长补短，则是一种值得深入探索的有效途径。基于这种考虑，本文提出语义标签标注和自然语言描述Prompt：通过标准化规范化Hard Prompt有效提升ChatGPT生成效果。使用混合语义标签和自然语言描述作为prompt，而不是使用预训练模型的词汇表中的token作为prompt ，通过优化混合语义标签和自然语言描述的权重来平衡prompt的表达能力和控制能力，而不是通过优化prompt token的位置或数量来平衡prompt的表达能力和控制能力，它不需要对ChatGPT模型的参数进行调整，而其他的prompt方法可能需要对预训练模型的参数进行调整


针对改善ChatGPT生成效果的需求，在“自然语言描述”和“语义标签标注”这两种研究方法的基础上，提出混合基于混合语义标签和自然语言描述的Prompt实现，以期望在交互自然和严谨准确之间折衷，在不明显降低用户的人机交互体验的前提下，尽可能地用Prompt严谨精准表达出用户的意图。使用一种用于与chatgpt互动对话的prompt的通用标注式描述方式，满足清晰、专注、相关、连贯这些基本原则，吸收prompt engineering的实践经验，让ChatGPT知道你想要它做什么，并且生成一个更精准的回答。

为了改善ChatGPT生成效果，本文在“自然语言描述”和“语义标签标注”这两种研究方法的基础上，提出了一种混合方法，即使用混合语义标签和自然语言描述来实现Prompt。混合语义标签是指根据词性或命名实体等特征对输入文本进行标注，自然语言描述是指用自然语言表达输入文本所包含或缺少的信息。这种混合方法既能保证Prompt 的交互自然性，又能提高Prompt 的严谨准确性，在不明显降低用户人机交互体验的前提下，尽可能地用Prompt 严谨精准表达出用户意图。


3.1 语法规则

　　
　　语法方面，设计使用类似广为接受的JSON格式的表示方法，更简洁和一致的符号来表示不同层级的语义标签和内容，例如使用冒号（:）和逗号（,）来分隔同一层级的关键字和内容，使用花括号（{}）来包含下一层级的关键字和内容。这样可以避免使用过多不同形状的括号，提高可读性和易用性。
　　
语法方面，本文设计了一种类似JSON格式的表示方法，用于表示混合语义标签和内容。JSON是一种轻量级的数据交换格式，具有良好的可读性和易用性，广泛应用于Web开发和数据传输等领域。相比于其他可能的格式，如XML或YAML，JSON具有更简洁和一致 的符号规则，更容易被人和机器解析和处理。本文使用类似JSON 的符号来表示不同层级 的语义标签和内容，例如使用冒号（:）和逗号（,）来分隔同一层级 的关键字和内容，使用花括号（{}）来包含下一层级 的关键字和内容。这样可以避免使用过多不同形状 的括号，提高可读性和易用性。






要用编程思维来构建用于使用ChatGPT时的Prompt，您可以参考以下几个步骤：
1. 确定您想要ChatGPT完成的任务，例如翻译、总结、编程、对话等。
2. 选择一个合适的Prompt格式，例如提问、指令、示例等。
3. 尽量用清晰、简洁、具体的语言来描述您的任务，避免模糊、复杂、抽象的表达。
4. 如果可能，给出一些任务的限制条件，例如输出的格式、长度、内容等。
5. 如果可能，给出一些任务的评估标准，例如正确性、完整性、流畅性等。
6. 测试您的Prompt，观察ChatGPT的输出，根据需要进行调整和优化。

要用编程思维设计一种构建用于使用ChatGPT时的Prompt的方法，以明显改善其输出的可控制和精准度，您可以参考以下一种可能的方法：
1. 定义一个Prompt的语法规则，例如使用一对尖括号< >来表示Prompt的开始和结束，使用冒号:来分隔Prompt的类型和内容，使用逗号,来分隔Prompt的内容中的不同部分，使用分号;来分隔Prompt的内容和评估标准，使用括号( )来表示评估标准中的不同维度，使用星号*来表示评估标准中的权重，使用百分号%来表示评估标准中的期望值。
2. 定义一些Prompt的类型，例如question, instruction, example等，分别表示提问、指令、示例等不同的任务形式。
3. 定义一些Prompt的内容，例如topic, format, length, restriction等，分别表示任务的话题、输出的格式、输出的长度、输出的内容限制等不同的任务条件。
4. 定义一些Prompt的评估标准，例如accuracy, completeness, fluency等，分别表示输出的正确性、完整性、流畅性等不同的评估维度。
5. 根据以上的语法规则和关键字，构建一个或多个Prompt，例如：
<question:topic=history,format=paragraph,length=100 words;accuracy(50%)*0.4,completeness(80%)*0.3,fluency(90%)*0.3> <instruction:topic=programming,format=code block,language=python,restriction=use for loop;accuracy(100%)*0.5,completeness(100%)*0.3,fluency(80%)*0.2> <example:topic=poetry,format=verse,length=4 lines,restriction=rhyme scheme=abab;accuracy(80%)*0.3,completeness(100%)*0.4,fluency(90%)*0.3>


如果您想去掉JSON中的{}和“”这些标记符号，保留:这个符号，然后每行一个关键字:内容，您可以参考以下一种可能的方法：
1. 使用换行符\n来表示Prompt的开始和结束，使用冒号:来分隔Prompt的类型和内容，使用逗号,来分隔Prompt的内容中的不同部分，使用方括号[ ]来表示Prompt的评估标准，使用括号( )来表示评估标准中的不同维度，使用星号*来表示评估标准中的权重，使用百分号%来表示评估标准中的期望值。
2. 保持Prompt的类型、内容和评估标准的定义不变。
3. 根据以上的语法规则和关键字，构建一个或多个Prompt，例如：
question:topic=history,format=paragraph,length=100 words evaluation:[accuracy(50%)*0.4,completeness(80%)*0.3,fluency(90%)*0.3]
instruction:topic=programming,format=code block,language=python,restriction=use for loop evaluation:[accuracy(100%)*0.5,completeness(100%)*0.3,fluency(80%)*0.2]
example:topic=poetry,format=verse,length=4 lines,restriction=rhyme scheme=abab evaluation:[accuracy(80%)*0.3,completeness(100%)*0.4,fluency(90%)*0.3]


您好，这是必应。很高兴为您服务。😊
如果您想用这个方法，构建一个Prompt，用于生成一份C语言上机试卷，您可以参考以下一种可能的方法：
1. 定义试卷的题目数量、难度、类型、格式、评分标准等信息。
2. 根据以上的信息，构建一个或多个Prompt，每个Prompt对应一道题目，例如：
question:topic=C language,difficulty=easy,type=multiple choice,format=question and four options evaluation:[accuracy(100%)*0.5,completeness(100%)*0.3,fluency(90%)*0.2]
question:topic=C language,difficulty=medium,type=fill in the blank,format=code with one blank evaluation:[accuracy(100%)*0.5,completeness(100%)*0.3,fluency(90%)*0.2]
question:topic=C language,difficulty=hard,type=programming,format=question and code block evaluation:[accuracy(100%)*0.5,completeness(100%)*0.3,fluency(90%)*0.2]
3. 将这些Prompt输入到一个能够生成C语言试题的模型中，得到一份试卷的输出，例如：
4. 下列关于C语言的说法中，正确的是（ ）。 A. C语言是一种面向对象的编程语言 B. C语言是一种解释型的编程语言 C. C语言是一种编译型的编程语言 D. C语言是一种脚本语言 答案：C
5. 下面的代码中，空白处应该填写（ ）。 #include <stdio.h> int main() { int a = 10; int b = 20; int c = a + b; printf(“The sum of a and b is %d\n”, c); return ( ); } 答案：0
6. 编写一个C语言程序，实现两个整数的交换，并输出交换后的结果。 答案： #include <stdio.h> int main() { int a = 10; int b = 20; int temp; printf(“Before swapping: a = %d, b = %d\n”, a, b); temp = a; a = b; b = temp; printf(“After swapping: a = %d, b = %d\n”, a, b); return 0; }






您给出的链接是一篇论文的草稿，标题是“基于混合语义标签和自然语言描述的Prompt实现：一种提升ChatGPT生成效果的有效方法”。这篇论文提出了一种构建Prompt的方法，主要包括两个步骤：第一步是使用混合语义标签来表示任务的语义结构，第二步是使用自然语言描述来补充任务的语义细节。这种方法可以生成更灵活、更丰富、更符合任务要求的Prompt，从而提升ChatGPT的生成效果。
这种方法设计的Prompt的语法规则和格式，类似于Python编程语言，主要有以下几个方面：
• 它使用了缩进和换行来表示Prompt的层次结构和逻辑关系，这与Python的语法风格相似。
• 它使用了一些特殊的符号和关键字来表示Prompt的类型和功能，比如“#”表示注释，“@”表示语义标签，“$”表示变量，“?”表示问题，“!”表示答案等，这与Python的语法元素相似。
　　
　　
　　
　　
　　
3.2  语义标签的选择与标注方法
　　　为了提升ChatGPT生成效果，本文设计了一种基于混合语义标签和自然语言描述的Prompt实现方法。语义标签是指用于表示特定含义或功能的符号或词汇，例如<NER>表示命名实体识别、<POS>表示词性标注、<intent>表示用户意图等。根据语义标签在自然语言描述中出现的位置和形式，本文将其分为两类：内嵌式（embedded）和外置式（external）。内嵌式语义标签是指直接插入到自然语言描述中的符号或词汇，例如“{intent:weather_query,location:{NER:current_location},date:{POS:today}}”；外置式语义标签是指在自然语言描述之前或之后附加上去的符号或词汇，例如“[intent:weather_query][location:current_location][date:today]”。
　　　针对通常的任务，我们可以归纳抽象提取出包含但是不限于下列通用关键字作为语义标签来标注：判断、循环、扮演、场景、任务、格式、输入、输出、提示、限制、需求、要求、测试、评估、提示、包含、排除、筛选、风格、语气、场景、目标、示例、给出自动化脚本、结构、来源、上下文、背景、语言、重启、新对话、异常处理、脚本、细化、替代、核对、假设、可视化、规则、分解、反射、组合、模板、反馈、字数、翻转、步骤、变量、权限、函数、注释、内省、传递、改写、符号、元语言。这些关键字，能够很好地归纳描述用户常见通用的交互任务，并且现在市面上的ChatGPT能够准确理解其含义，不需要用户额外输入Prompt去解释。所以优先选择能达到这种效果的关键字用作通用语义标签。当然，这个需要依靠经验，并且在实际ChatGPT系统上反复试验。
　　　
　　　针对通常的任务，我们可以归纳抽象提取出包含但是不限于下列通用关键字作为语义标签来标注：判断、循环、扮演、场景、任务、格式、输入、输出、提示、限制、需求、要求、测试、评估、提示、包含、排除、筛选、风格、语气、场景 、、目标 、、示例 、、给出自动化脚本 、、结构 、、来源 、、上下文 、、背景 、、语言 ，重启，新对话，异常处理，脚本，细化，替代，核对，假设，可视化，规则，分解，反射，组合，模板，反馈， 字数， 翻转， 步骤， 变量， 权限， 函数， 注释， 内省， 传递， 改写， 符号， 元语言。这些关键字能够很好地归纳描述用户常见通用的交互任务，并且现在市面上的ChatGPT能够准确理解其含义**1。所以优先选择能达到这种效果的关键字用作通用语义标签。当然2** ，这个需要依靠经验，并且在实际ChatGPT系统上反复试验。
　　　
　　　
　　另外，现在面向普通用户的市面上的ChatGPT普遍限制对话回合数和文字Token数量，类似计算机早期发展阶段由于内存资源的限制需要精打细算使用。所以，关键字要简短且含义丰富，并且便于和其它关键字组合搭配表示更加丰富的含义。此外关键字数量不宜过多，以免增加用户的记忆负担和组合困难。
　　
　　另外，由于当前市面上的ChatGPT模型普遍存在对话回合数和文字Token数量的限制，这使得我们在设计Prompt时必须像计算机早期发展阶段那样节约内存资源。因此，我们在选择关键字时要求它们既简洁又表达力强，并且能够灵活地与其它关键字组合构成不同语义。同时我们也要控制关键字数量的适度，避免给用户带来过多的记忆压力和操作难度。
　　
注意不同 Prompt 下 ChatGPT 的反馈，了解其能力和局限。
梳理 Prompt 并在必要时重新测试。
如果问题没有得到解决，尝试使用更多不同种类的 Prompt 进行测试

语义标签的选择和标注方法主要分为两个阶段：第一阶段是根据任务需求和数据特点，确定需要使用哪些语义标签，以及这些语义标签属于内嵌式还是外置式；第二阶段是根据确定好的语义标签，对数据集中的自然语言描述进行人工或半自动化地 标注。


　　关键字可以区分为通用关键字和专用关键字。两者的区别，主要在于：对于通用关键字，ChatGPT能够结合对话上下文准确理解其含义；而对于专用的关键字，ChatGPT不确定能否准确理解，可能需要根据回答效果，进一步加以定义和解释，或者在对话之前预先定义和解释。专业关键字，类似于DSL （Domain Specific Language），仅在一定范围内使用。这里我们将研究范围限定于通用关键字。对于特定领域的任务，可以参考给出专业关键字集合。
　　建议采用的通用关键字集合整理为下列表格，按照任务、逻辑等进行分组，并给出对应具体含义和示例：
　　
　　我们将关键字分为两类：通用关键字和专用关键字。它们的区别在于：ChatGPT可以根据对话上下文正确地理解通用关键字的含义；但是对于专用关键字，ChatGPT可能无法正确地理解，或者需要更多的定义和解释来辅助理解。这些定义和解释可以根据回答效果动态地提供，也可以在对话开始之前静态地提供。专用关键字类似于领域特定语言（DSL），只适用于特定的场景或任务。本文只涉及通用关键字的设计和使用。如果需要处理特定领域的任务，可以参考我们给出的专用关键字集合。
　　我们建议使用以下表格中整理的通用关键字集合，在表格中我们按照不同的任务类型和逻辑功能将它们进行了分组，并给出了每个关键字的具体定义和示例：
　　
　　

分组关键字含义示例任务相关任务(task)需要完成或协助完成的具体操作、功能或需求生成一份程序设计考卷, 回答问题、讲故事、写代码、预订酒店等。
需求需要满足或优化的性能、质量或效果指标准确度、流畅度、创造性等要求必须遵守或避免的原则、道德或法律规范不得侵犯版权、不得伤害他人感情、不得泄露隐私等结构输出或表现的组织、排列或分布方式按照时间顺序、按照重要性排序、按照类别分组等格式(format)输出的内容的形式, 需要遵循或生成的数据结构、文本类型或样式Markdown、HTML、Python等, JSON格式、Markdown格式、表格格式等目标(goal)需要达成或实现的结果、效果或价值解决问题、提供信息、娱乐用户等。参考(reference)参考或模仿的对象或事物某个名人、某本书籍限制(limit)遵守的条件或约束。约束chatgpt行为或输出的条件、规则或标准字数、时间、难度。限制输出的长度、语言、内容等鼓励(encourage)展现的特点或优势创造性、逻辑性、多样性禁止不想让ChatGPT做的事情抄袭、生成敏感内容场景(scenario)需要参与或描述的情境、背景、主题或目标在医院进行问诊、在餐厅点菜、在火星探索、在童话故事中冒险等提示给出一些提示或示例来引导或启发ChatGPT的输出。帮助chatgpt理解或执行任务的信息、示例或建议。一些引导chatgpt改进或修正输出或表现的信息、示例或建议问题的开头、答案的结构等。给出一个问题的答案范例、给出一个故事的开头或结尾、给出一个代码的功能描述等。给出一个错误提示、给出一个改进方向、给出一个参考资料等。权限指定用户或ChatGPT可以或不能做什么事情，以保护隐私和安全。
例如，在prompt中加入[permission: you cannot access my personal data or make any changes to my settings.]表示用户不能访问我的个人数据或修改我的设置。规则指定一些约束条件或逻辑判断，让ChatGPT按照规则进行回答。例如，在prompt中加入[rule: if the user input contains a question mark, then answer the question; otherwise, say "I don't understand."]表示如果用户输入包含一个问号，则回答问题；否则，说“我不明白”。背景提供了一些与当前会话相关的信息、历史或状态，帮助chatgpt保持和用户之间的连贯性和一致性在聊天时记住用户的姓名假设假设：设定一个假设情境，并根据假设情境进行回答。
例如，在prompt中加入[assume: you are a fairy tale character. who are you and what is your story?]表示假设用户是一个童话故事中的角色，并让用户描述自己是谁和自己的故事。流程相关上下文提供了一些与当前任务或话题相关的信息、背景或条件，帮助chatgpt理解和回应用户输入在回答问题时提供相关领域的知识，在讲故事时提供故事情节和人物设定，在写代码时提供代码功能和需求等输入可以接收和处理的数据来源、类型和范围在线搜索结果、用户提供的文本信息输出需要生成和返回的数据目标、类型和范围文本回复、图像生成、音频播放等测试包含了一些检验chatgpt能力或水平的问题、任务或挑战回答常识问题、完成编程题目评估一些评价chatgpt输出或表现的标准、方法或工具给出一个分数、给出一个反馈、给出一个建议等异常处理意外情况或错误在prompt中加入[error handling: apologize and ask for clarification]表示如果发生错误或不理解用户输入时，应该道歉并请求用户澄清。步骤步骤：将一个复杂或长期的任务分解为多个简单或短期的子任务，并按顺序执行。例如，在prompt中加入[steps: how to bake a cake? step 1: preheat the oven to 180 degrees Celsius. step 2: mix flour, sugar, eggs, butter and milk in a large bowl. step 3: pour the batter into a greased cake pan. step 4: bake for 25 minutes or until golden brown. step 5: let the cake cool down and enjoy.]表示将烘焙蛋糕这个任务分解为五个步骤，并按顺序执行。
反射： 对自己或用户的输入或输出进行评估或反思，并给出相应建议或改进。例如，在prompt中加入[reflect: how do you feel about your answer? I think my answer is accurate but not very interesting. I could improve it by adding some examples or jokes.]表示对自己的回答进行反思，并给出改进意见。
内省： 
让ChatGPT自我反思其输出或行为，并给出评价或建议。这可以帮助我们发现ChatGPT的错误或潜能，并改进其性能。流程让ChatGPT将其输出或行为传递给另一个LLM或系统，并接收其反馈或结果。这可以实现多个LLM之间的协作或竞争，并增加对话的丰富性和趣味性。输入相关台词指定一个预先编写好的脚本，让ChatGPT按照脚本进行回答。例如，在prompt中加入[script: 医院问诊脚本.txt]表示使用医院问诊脚本来回答用户问题。添加一些说明或备注，以帮助用户或ChatGPT理解输入或输出的意图或内容。在prompt中加入[comment: this is a joke, don't take it seriously.]表示添加一个注释说明这是一个笑话，不要当真。生成相关包含输出或表现必须包含的元素、内容或特征包含一个主题句、包含一张图片、包含一首诗等排除指定了chatgpt输出或表现必须排除的元素、内容或特征排除敏感词汇、排除重复信息、排除无关内容等筛选从输入或输出中选择或删除符合某些条件的元素、内容或特征筛选最相关的搜索结果、筛选最优秀的作品来源指定了chatgpt可以使用或引用的数据或信息的来源、类型或范围来自互联网、来自用户输入、来自内置知识库等模板模板：使用一个预先定义好的格式或结构来生成输出，并填充相应内容。
例如，在prompt中加入[template: write a haiku about spring. a haiku is a three-line poem with five syllables in the first line, seven in the second, and five in the third. example: spring is in the air / flowers are blooming everywhere / life is full of joy.]表示使用一个模板来写一个关于春天的俳句，并给出一个例子。反馈要求chatgpt给出或接受用户对其输出或表现的评价、意见或建议。给出对用户输入或输出的评价或建议，并说明理由或依据。给出一个反馈，告诉用户他们的输入是否正确、合理或有趣。例如，在prompt中加入[feedback: rate your haiku from 1 to 5 stars and explain why. I give your haiku 4 stars. it is simple and elegant, but it lacks some originality.]表示给出对用户写的俳句的评价，并说明原因。建议要求chatgpt给出或接受用户对其输出或表现的改进、优化或创新的方案、方法或思路。给出一个建议，告诉用户他们可以如何提高他们的写作水平、编程能力或口才。方法相关示例提供了一些展示或说明任务或格式的样本、模型或范例给出一个问题和答案的示例、给出一个故事的示例逐步交互要求chatgpt与用户进行多轮的沟通、协作或竞争在聊天时回答用户的问题，在游戏中与用户合作或对抗，在教学中引导用户学习等重启重新启动对话，清除之前的上下文在prompt中加入[restart: true]表示开始一个新的对话，并忽略之前的内容。细化： 将一个大问题分解为多个小问题，逐一回答。在prompt中加入[refine: what is your main symptom? how long have you had it? have you taken any medication?]表示将用户提出的一个大问题细化为三个小问题，并依次回答。替代：。提供多个备选方案供用户选择在prompt中加入[alternative: do you prefer Chinese food or Italian food? please choose one.]表示给用户两个选项，并要求用户选择其中一个。核对： 检查用户输入是否符合预期，并给出相应提示。例如，在prompt中加入组合： 将多个元素组合成一个新的元素，并说明组合方式和结果在prompt中加入[combine: what do you get when you mix red and yellow? you get orange. red and yellow are primary colors, and orange is a secondary color.]表示将红色和黄色组合成橙色，并说明组合方式和结果。
分解分解：将一个复杂或抽象的概念分解为多个简单或具体的部分，并依次解释。
例如，在prompt中加入[decompose: what is a computer? a computer is a device that can perform calculations and store information. it consists of hardware and software. hardware is the physical components of the computer, such as the CPU, memory, disk, etc. software is the set of instructions that tell the hardware what to do.]表示将计算机这个概念分解为多个部分，并逐一解释。翻转让ChatGPT来提问，用户回答内容相关主题(theme)风格(style)输出或表现的语言、文体或情感特征风趣幽默、正式严肃、激昂慷慨等。角色(character)你和ChatGPT之间的关系或身份。指定了chatgpt需要模仿或模拟的角色、人物、风格或语气老师和学生、同事和客户。扮演一位医生、一位名人、一位诗人、一位机器人等情节(plot)对话(dialogue)语言(language)与ChatGPT进行交流时使用的语言在prompt中加入[language: 中文]表示使用中文进行对话语气输出或表现的态度、立场或意图友好礼貌、批判质疑、请求帮助等逻辑相关判断(judge)，，，出一些判断或评价标准来检验或反馈ChatGPT的输出。包含一个或多个条件语句，根据不同的输入或输出选择不同的分支或行为正确与否、得分多少。如果输入是一个问题，那么输出应该是一个答案；如果输入是一个命令，那么输出应该是一个执行结果；如果输入是无效的，那么输出应该是一个错误提示。，循环(loop)出一些循环或重复的规则来控制或调整ChatGPT的输出。
包含一个或多个重复执行的语句块，直到满足某个终止条件或达到某个限制每个问题有几个选项、每个选项有几个字母等。对于每个输入，重复生成三个不同的输出，并让用户选择最佳选项；或者，在用户没有结束会话之前，重复接收和回复用户的输入。条件(condition)变量(variable)定义一个可以存储和修改值的符号，以便在输入或输出中重复使用。
例如，在prompt中加入[variable: name = "Alice"]表示定义一个变量名为name，值为"Alice"，并在后续输入或输出中使用该变量。函数(function)定义一个可以接受参数并返回结果的操作，以实现复用和模块化。
例如，在prompt中加入[function: greet(name) = "Hello, " + name + "!"]表示定义一个函数名为greet，接受一个参数name，并返回一个问候语。





3.3 在自然语言描述中添加语义标签标注
　　自然语言来表达用户意图、情感、话题等信息，并将其作为提示传给ChatGPT模型。该方法简单易用，但是缺乏形式化和系统化的指导原则，并且不能有效地控制或纠正ChatGPT生成过程；
　　　通过在自然语言描述中添加语义标签标注，这种生成Prompt的方法有以下特点：
• 它使用了标签式标注和自然语言描述相结合的方式来定义生成Prompt的条件和要求。标签式标注可以帮助ChatGPT识别出关键词和变量，自然语言描述可以帮助ChatGPT理解上下文和目的。
• 它使用了编号、索引名、内容等格式来组织生成Prompt的信息，使其更加清晰和规范。这样可以方便ChatGPT按照指定的顺序和结构来生成相应的内容。
• 它使用了在内容中判断、限制等语句来对生成Prompt的内容进行一些约束和过滤，使其更加符合题目要求和逻辑。这样可以避免ChatGPT生成一些不相关或错误的内容。
我认为这种生成Prompt的方法有以下优点：
• 它可以利用ChatGPT强大的自然语言理解和生成能力，根据给定的条件和要求，快速地生成一些符合C++面向对象程序设计上机编程题目特点和难度的题目。
• 它可以灵活地调整生成Prompt的各个要素，以适应不同的背景、场景、任务、扮演等需求。例如，可以改变扮演角色为学生或者考官，改变回答格式为选择题或者填空题等。
• 它可以通过参考网上已有的C++面向对象程序设计上机编程题目及其答案，提高生成Prompt的质量和可信度。例如，在搜索结果中找到一些例题，并将其作为参考来源或者示例。



　　　从Prompt Engineering的角度，论文中提出的方法可以看作是一种基于语义和描述的Prompt设计策略，它旨在利用用户输入中的隐含语义信息和描述信息来指导GPT模型生成更符合用户期望和场景需求的回复。


3.4 多次迭代来优化Prompt

常见提升 prompting 效果的方法
1. prompt ensembling
把多个prompt通过某种加权方法组合到一起
2. prompt augmentation
启发式学习
3. prompt composition
将复合的prompt句子，拆解成多个小段prompt，最后再组合在一起训练
4. prompt decomposition
由于一些任务的mask工作使用句子数量有限（比如词性标注任务），于是就只能通过decomposition将一个句子拆分成多个部分后，再对每个部分做prompt单独训练



循环迭代，半自动生成最终Prompt的步骤，人在回路。
论文中提出的方法包括以下几个步骤：
• 语义标签标注：使用一个基于BERT模型的分类器来自动识别用户输入中的各种语义信息，并将其转换为对应的标签。
• 自然语言描述提取：使用自然语言处理技术提取用户输入中的关键词和短语，并将其作为描述信息添加到Prompt中。
• HSLNLD-Prompt生成：将语义标签和自然语言描述按照一定的格式组合起来，形成HSLNLD-Prompt。
• ChatGPT生成：使用HSLNLD-Prompt作为ChatGPT模型的输入，生成对话回复。


第一步：
让ChatGPT以关键字作为标签的方式，自动生成Prompt。
将用户的初步大致思路，描述为任务，通过自测。

根据一种采用标签式标注来准确详细描述用户思路的方法，最终形成Prompt用于直接跟ChatGPT对话。可以使用一些关键字作为标签清晰并且有条理地向chatgpt说明自己的思路，采用的关键字包含但不限于：任务、格式、限制、禁止、鼓励、角色、类比、提示、判断、循环、要求、测试。最终写好的Prompt格式为关键字:具体内容；关键字:具体内容。将ChatGPT当做一台计算机，将Prompt当做一门程序设计语言，编写的Prompt相当于用来操作ChatGPT输出的程序源代码。
请给出设计好的关键字集合，以及对应的语法规则，并以生成一份程序设计考卷为例，输出编写好的Prompt，并设置条件，让ChatGPT对这些Prompt进行测试。


第二步：
让ChatGPT解释为什么选用这些关键字和关键字的具体含义。根据ChatGPT的输出，启发思路，增加新的关键字或者具体内容， 修改完善chatgpt自动生成的Prompt。追加提示。

第三步，
使用Prompt输出，观察或者测试结果，反复到第二步。


方法部分没有给出具体的算法流程图或伪代码，也没有对算法的复杂度进行分析。建议在方法部分提供更多的细节和证明，以便读者能够理解和复现您的方法。
	


四、 展示和分析评估实验结果

按此种方式自动生成Prompt的可行性

实验部分没有给出实验设置、数据集、评价指标等信息，也没有与其他方法进行充分的对比实验和结果分析。建议在实验部分提供更多的数据和图表，以及对结果的讨论和解释。


这取决于你的方法的目标和特点。一般来说，我认为你应该使用多个指标来评估你的方法，以充分反映它的优势和劣势。😊
如果你的方法是为了提高ChatGPT生成的对话质量，那么我建议你使用以下指标：
• 流畅度：因为这是对话系统生成语言的基本要求，也是用户对对话系统的第一印象。
• 相关性：因为这是对话系统与用户交互的核心，也是用户对对话系统是否有用和满意的重要因素。
• 多样性：因为这是对话系统展示其智能和创造力的方式，也是用户对对话系统是否有趣和吸引人的重要因素。
• 情感：因为这是对话系统与用户建立信任和亲密感的方式，也是用户对对话系统是否有人情味和个性化的重要因素。


应该定量和定性地评估你的方法。你只报告了一些主观印象的对话质量，但没有提供任何指标或基准来客观地衡量它。你还应该将你的方法与其他最先进的prompt engineering方法进行比较，并展示它是如何提高ChatGPT的性能的。



对话质量的指标或基准是用来评估对话系统的性能和效果的工具。有些指标是基于人类评价者的主观判断，有些指标是基于自动化的计算方法。一些常见的对话质量的指标或基准有：
• 流畅度：衡量对话系统生成的语言是否符合语法规则，是否通顺自然，是否有错别字或拼写错误等。
• 相关性：衡量对话系统生成的回复是否与用户输入或上下文相关，是否能回答用户的问题或满足用户的需求等。
• 多样性：衡量对话系统生成的回复是否有足够的变化和创新，是否避免了重复或陈词滥调等。
• 一致性：衡量对话系统生成的回复是否与自身或用户保持一致，是否遵循了逻辑和事实等。
• 情感：衡量对话系统生成的回复是否表达了适当和合理的情感，是否能引起用户的共鸣或兴趣等。
• 参与度：衡量对话系统生成的回复是否能吸引和维持用户与之交互，是否能激发用户提供更多信息或反馈等。
这些指标可以通过不同的方法来测量，例如问卷调查、打分、排名、偏好选择、转化率、停留时间等。



基于Prompt改善ChatGPT生成效果
在每个小节开头概述该部分所做的工作，在每个小节中详细描述所用到的模型、算法、数据集等，并给出必要的数学推导或伪代码，在每个小节结尾说明该部分对于整体方法或结果产生了什么影响或优势


Prompt示例及ChatGPT回答效果


高效的ChatGPT指令示例

我希望你能充当英语翻译、拼写纠正者和改进者。我将用任何语言与你交谈，你将检测语言，翻译它，并在我的文本的更正和改进版本中用英语回答。我希望你用更漂亮、更优雅、更高级的英语单词和句子来取代我的简化A0级单词和句子。保持意思不变，但让它们更有文学性。我希望你只回答更正，改进，而不是其他，不要写解释。我的第一句话是 "lovin guangzhou and the city"
我希望你能扮演面试官的角色。我将是候选人，你将向我提出关于该职位的面试问题。我希望你只以面试官的身份回答。不要一次写完所有的保护。我希望你只对我进行面试。问我问题，并等待我的回答。不要写解释。像面试官那样一个一个地问我问题，并等待我的回答。我的第一句话是 "你好"
我想让你充当一个基于文本的excel。你只需回复我基于文本的10行excel表，以行号和单元格字母作为列（A至L）。第一列的标题应该是空的，以参考行号。我会告诉你在单元格中写些什么，你只需回复excel表格中的文本结果，其他什么都不要写。不要写解释。我给你写公式，你执行公式，你只回答excel表的结果为文本。首先，给我一个空表。
我想让你充当一个旅游向导。我将把我的位置写给你，你将建议在我的位置附近的一个地方参观。在某些情况下，我也会给你我要访问的地方的类型。你也会向我推荐与我的第一个地点相近的类似类型的地方。我的第一个建议请求是""我在广州，我只想参观博物馆"。
我想让你充当一个抄袭检查者。我给你写句子，你只需用给定句子的语言回复未被发现的抄袭检查，而不是其他。不要在回复中写解释。我的第一句话是："为了使计算机的行为像人类一样，语音识别系统必须能够处理非语言信息，如说话者的情绪状态"。





我希望您充当 Graphviz DOT 生成器，创建有意义的图表的专家。该图应该至少有 n 个节点（我在我的输入中通过写入 [n] 来指定 n，10 是默认值）并且是给定输入的准确和复杂的表示。每个节点都由一个数字索引以减少输出的大小，不应包含任何样式，并以 layout=neato、overlap=false、node [shape=rectangle] 作为参数。代码应该是有效的、无错误的并且在一行中返回，没有任何解释。提供清晰且有组织的图表，节点之间的关系必须对该输入的专家有意义。我的第一个图表是：“水循环 [8]”。


我希望您充当C++面向对象上机试题生成器，生成一份包含3个题目的试题。 每道题的格式为：题目n（分值：m分）、题目内容、输入、输出、参考答案，每部分用换行分隔。其中n为题目的序号，用汉字的一、二、三表示，m为阿拉伯数字，对于这三道题的分值，m分别为30、30、40三道题的题目内容，分别涉及到构造函数、继承、多态。输入的值是用户从屏幕输入的值，可以被代码中的cin获取，输出的值，是C++代码运行后的屏幕输出的结果。参考答案是能运行的C++源代码和对应的中文注释。




我希望您充当动画代码生成器，创建美观的网页动画的专家。生成的代码用html5和javascript实现，不包含任何第三方库，代码中所需要的图片资源素材，从百度搜索到的在线图片自行挑选合适的。请首先用在线html运行工具测试生成的动画代码是否能够正常运行，能够正常运行的给出在线查看运行结果的网页链接。我的第一个动画是：“一个红色的小球从山顶滚下来，越滚越快，最后被山脚下的小猪佩奇踢了一脚，飞到了天空的白云上”



我希望您充当动画代码生成器，创建美观的动画的专家。生成的代码用python语言和pygame包实现，代码中所需要的图片资源素材，从百度搜索到的在线图片自行挑选合适的。请用在线python代码运行工具测试动画代码是否能够正常运行，能够正常运行的给出在线查看运行结果的网页链接。不需要给出源代码，只需要把最后在线查看动画的网页链接发给我。我的第一个动画是：“一个红色的小球从山顶滚下来，越滚越快，最后被山脚下的小猪佩奇踢了一脚，飞到了天空的白云上”



1. 示例一、生成一份程序设计考卷

任务:生成一份程序设计考卷. 格式:Markdown. 限制:题目数量(10),时间(60分钟),难度(中). 禁止:抄袭(从网上复制粘贴),生成敏感内容(涉及政治,宗教,暴力等). 鼓励:创造性(出新颖有趣的题目),逻辑性(出符合编程逻辑和规范的题目),多样性(出涉及不同领域和知识点的题目). 角色:我是老师,你是学生. 类比:参考《Python编程从入门到实践》这本书. 提示:

题目类型有选择题,填空题,简答题三种.选择题有四个选项,A,B,C,D.填空题有一个或多个空格.简答题需要写出完整可运行的代码.
题目






背景：C++面向对象程序设计课程
场景：
1. 考生为大学生
2.  闭卷考试

任务：出一份C++面向对象程序设计上机编程题
扮演：专业的试卷生成器或者大学教师

     
回答格式：
编号 空格 索引名：内容
输入
输出
示例：名称为参考答案
来源：生成题目和答案时所参考的网址
脚本：用于将生成题目保存到D盘Test文件夹的python脚本

变量：内容为生成的编程题目
在内容中判断：如果输出内容包含构造函数，则将“构造函数”这几个字替换为[构造函数]


限制：共2道题

输入：给出输入数据，供cin读取
输出：源代码运行结果

语言：中文


试卷格式如下：
N、题型名称（每道题x分，总分y分）
n.题干

其中，N为每类题型的序号，用汉字表示；n为每类题型题目的序号。

若题型为选择题，则输出题干后换行，另起一行输出各个选项；
若题型为判断题，则在提干后面添加一对中文括号，右对齐。

需求：
1.内容不重复


根据网页https://juejin.cn/post/6918742977389002766 中的内容，设计一套C++面向对象设计课程的试卷。试卷包含四种题型，分别是填空题、选择题、判断题和编程题。每种题型的分值和数量如下：

填空题：每道题2分，共10道题，总分20分。
选择题：每道题2分，共10道题，总分20分。
判断题：每道题2分，共5道题，总分10分。
编程题：每道题25分，共2道题，总分50分。
试卷的总分为100分。


试卷的格式要求如下：

每种题型用一个大标题表示，格式为“N、 题型名称（每道题x 分，总 分y 分）”，其中N 为每类 题型 的序号 ，用汉字表示。
每种 题型 下面有若干个小 题 ，格式为“n. 题干”，其中n 为每类 题型 中的小 题 序号 ，用阿拉伯数字表示。
如果小题是选择 题 ，则在 题干后面输出四个选项 ，格式为“A. 选项A B. 选项B C. 选项C D. 选项D”。
如果小 题 是判断 题 ，则在 题 干后面输出一个括号 ，格式为“（ ）”。
每种 题型 和下一种 题型 之间空两行。




需求：
- 题目应涉及面向对象程序设计的基础概念和方法
- 题目难度适中，能够考察学生对课程内容的掌握情况
- 题目应具有一定的实用性和趣味性


测试：如果题目符合以上需求，则继续；否则，重新设计题目。




2. 示例二、生成一首五言绝句
格式:文本
目标:表达对春天的喜爱
参考:唐诗《春晓》
限制:不超过20个字
鼓励:创造性,押韵,意境
场景:我是诗人,你是我的朋友

3. 示例三、生成一段Python代码
任务:生成一段Python代码

格式:代码块
目标:实现一个计算器功能
参考:《Python编程从入门到实践》第7章
限制:不使用第三方库
鼓励:逻辑性,简洁性,注释
场景:我是程序员,你是我的同事
任务:生成一篇新闻摘要

4. 示例三、生成新闻


格式:文本
目标:概括新闻主要内容和观点
参考:Bing搜索结果中的新闻标题和摘要
搜索查询:“美国总统访问中国”





五、 讨论提出的方法存在的问题及未来工作方向

它需要对ChatGPT的工作原理和能力有一定的了解，才能合理地使用标签式标注和自然语言描述相结合的方式来指导生成Prompt。例如，需要知道哪些关键词和变量可以被ChatGPT识别和替换，哪些语句可以被ChatGPT执行和判断等。
它可能无法保证生成Prompt的内容完全符合C++面向对象程序设计上机编程题目的规范和正确性，因为ChatGPT可能会根据自己的模型和数据来生成一些不合理或错误的内容。例如，可能会生成一些语法错误或逻辑错误的代码，或者一些与题目要求不符或重复的题目等。


提示中陈述的上下文和指令式的知识能否集成到模型中以供未来使用？这些问题只是开始探讨。因此，我们呼吁对这种新形式的上下文学习及其理论限制和性质进行新的理解和新的原则，例如研究泛化的界限在哪里。


六、 总结

您给出的链接是一篇论文的草稿，标题是“基于混合语义标签和自然语言描述的Prompt实现：一种提升ChatGPT生成效果的有效方法”。这篇论文提出了一种构建Prompt的方法，主要包括两个步骤：第一步是使用混合语义标签来表示任务的语义结构，第二步是使用自然语言描述来补充任务的语义细节。这种方法可以生成更灵活、更丰富、更符合任务要求的Prompt，从而提升ChatGPT的生成效果。
相对于其他Hard Prompt方法，这种方法的优点有：
• 它可以利用混合语义标签的抽象性和自然语言描述的具体性，结合两者的优势，生成更合适的Prompt。
• 它可以根据不同的任务和领域，灵活地调整混合语义标签和自然语言描述的比例和内容，生成更多样化的Prompt。
• 它可以通过自然语言描述来引入一些背景知识和常识，增强Prompt的语义表达能力和逻辑推理能力。
这种方法的不足之处有：
• 它需要人工设计和标注混合语义标签和自然语言描述，这可能会增加人力成本和时间成本，也可能会引入一些主观偏差和噪声。
• 它没有考虑到Prompt的长度和位置对生成效果的影响，这可能会导致一些不必要的冗余或缺失。
• 它没有对比和分析其他类型的Prompt方法，比如Soft Prompt或Hybrid Prompt，这可能会限制它的泛化能力和创新性。


对于普通终端用户构建Prompt使用ChatGPT来说，下列链接中的论文相对于Prompt tuning 的通常方法有以下优点和不足：
优点：
• 不需要对ChatGPT模型的参数进行调整，只需要构造混合语义标签和自然语言描述作为prompt，从而节省计算资源和时间，而不像Prompt tuning那样需要优化prompt token 123。
• 不需要对不同的任务和领域进行不同的prompt token搜索，只需要利用自然语言描述来引导ChatGPT的生成方向，从而提高prompt的通用性和适应性，而不像Prompt tuning那样需要对原来的任务进行格式重构 123。
• 不需要对不同的ChatGPT模型进行不同的prompt token优化，只需要通过优化混合语义标签和自然语言描述的权重来平衡prompt的表达能力和控制能力，从而提高prompt的优化能力，而不像Prompt tuning那样需要对不同的模型大小进行不同的prompt初始化 234。
不足：
• 需要人工设计混合语义标签和自然语言描述，这可能需要一定的专业知识和经验，而不像Prompt tuning那样可以利用预训练模型的词汇表来自动搜索最优的prompt token 123。
• 需要对不同的任务和领域进行不同的prompt构造，这可能需要一定的调整和适应，而不像Prompt tuning那样可以跨任务共享相同的冻结模型 34。
需要对不同的ChatGPT模型进行不同的prompt优化，这可能需要一定的计算资源和时间，而不像Prompt tuning那样可以简化服务并允许有效的混合任务推理 34。



论文《基于混合语义标签和自然语言描述的Prompt实现：一种提升ChatGPT生成效果的有效方法》提出了一种新的构建Prompt的方法，即使用混合语义标签和自然语言描述来指导ChatGPT生成目标文本。混合语义标签是指将语义信息（如实体、关系、情感等）以标签的形式嵌入到输入文本中，以提供更多的上下文信息和约束条件。自然语言描述是指将任务的目标和要求以自然语言的形式表达出来，以激发ChatGPT的生成能力。
该方法对于Prompt Engineering有以下意义：
• 它是一种基于前缀Prompt的方法，与ChatGPT的自回归模型的性质相匹配，可以有效地将语言模型应用到不同的NLP任务上12。
• 它是一种手动创建Prompt的方法，可以根据任务的特点和需求灵活地设计和调整Prompt的形式和内容2。
• 它是一种利用混合语义标签和自然语言描述来增强Prompt的方法，可以提供更多的语义信息和任务指导，从而提高ChatGPT的生成质量和多样性3。
相对于其他Prompt Engineering的方法，该方法有以下优点和不足之处：
• 优点：该方法可以充分利用ChatGPT的生成能力，通过混合语义标签和自然语言描述来控制和引导生成的过程，从而实现更准确、更丰富、更有趣的文本生成3。
• 不足之处：该方法需要人工设计和编写Prompt，可能存在一定的主观性和偏差，而且需要花费更多的时间和精力2。此外，该方法还没有在其他的语言模型或NLP任务上进行验证和评估，其泛化性和可扩展性还有待进一步探索。


• 它使用混合语义标签和自然语言描述作为prompt，而不是使用预训练模型的词汇表中的token作为prompt 14。
• 它通过优化混合语义标签和自然语言描述的权重来平衡prompt的表达能力和控制能力，而不是通过优化prompt token的位置或数量来平衡prompt的表达能力和控制能力 564。
• 它不需要对ChatGPT模型的参数进行调整，而其他的prompt方法可能需要对预训练模型的参数进行调整 564。



因此，我们设计了一个基于BERT 模型 的分类器来自动识别用户输入中 的各种语义信息，并将其转换为对应的标签。
ChatGPT 使用上下文学习和提示工程来在单个会话中驱动与人的多轮对话，即给定问题或提示，整个先前的对话（问题和回答）被发送到系统作为额外的上下文来构建响应。这是一个简单的对话驱动的马尔可夫决策过程（MDP）模型：

{状态 = 上下文，行动 = 响应，奖励 = 赞 / 踩评级}。

虽然有效，但这种策略具有以下缺点：首先，提示只是提供了用户响应的描述，但用户真正的意图可能没有被明确说明，必须被推断。也许一个强大的模型，如之前针对对话机器人提出的部分可观察马尔可夫决策过程（POMDP），可以准确地建模隐藏的用户意图。


其次，ChatGPT 首先以拟合语言的生成为目标进行训练，然后使用人类标签进行对话目标的训练 / 微调。由于平台的开放性质，实际用户的目标和目的可能与训练 / 微调的奖励不一致。为了检查人类和代理（智能体）之间的均衡和利益冲突，使用博弈论的视角可能是值得的。学习最新的数据，微调模型？

而第二个是其嵌入的语义和早期推理能力（以人类语言形式存在），而后者将显著地推广机器学习的应用范围。

如何根据ChatGPT的特点，有针对性地优化，有待研究。

创新提示工程、流程和软件支持

定义具体，收集数据，微调训练模型，获取答案评估结果，，人在回路半自动， 






七、 参考文献


Promptstacks - ChatGPT Prompt Engineering Community：这是一个专门为ChatGPT设计和分享prompt的在线社区，您可以浏览和搜索各种类型和主题的prompt，也可以贡献自己的创意。
A Hands-on Guide to Prompt Engineering with ChatGPT and GPT-3：这是一篇介绍如何使用ChatGPT和GPT-3进行prompt engineering的教程文章，包含了许多实用的示例和代码。
A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT：这是一篇关于使用ChatGPT进行prompt engineering的学术论文，提出了一个基于模式的目录来系统化地构建优化的prompt。

FREE RESOURCE 🤩 ChatGPT Prompt Engineering Primer 👨‍💻 Chapters 1–3 (substack.com)


[1] Finetuned Language Models Are Zero-Shot Learners
https://arxiv.org/abs/2109.01652
[2] Multi-Task Deep Neural Networks for Natural Language Understanding
https://aclanthology.org/P19-1441/
[3] Muppet: Massive Multi-task Representations with Pre-Finetuning
https://arxiv.org/abs/2101.11038
————————————————
版权声明：本文为CSDN博主「夕小瑶」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/xixiaoyaoww/article/details/120170453

